{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In the future `np.bool` will be defined as the corresponding NumPy scalar.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/guribeir/data_analysis_prem/confusion_matrix.ipynb Cell 1\u001b[0m in \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/guribeir/data_analysis_prem/confusion_matrix.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier(n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, class_weight\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/guribeir/data_analysis_prem/confusion_matrix.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m feat_selector \u001b[39m=\u001b[39m BorutaPy(rf, n_estimators\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/guribeir/data_analysis_prem/confusion_matrix.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m feat_selector\u001b[39m.\u001b[39;49mfit(X_train_final, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/guribeir/data_analysis_prem/confusion_matrix.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m selected_features_train \u001b[39m=\u001b[39m X_train_final[:, feat_selector\u001b[39m.\u001b[39msupport_]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/guribeir/data_analysis_prem/confusion_matrix.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m selected_features_test \u001b[39m=\u001b[39m X_test_final[:, feat_selector\u001b[39m.\u001b[39msupport_]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/boruta/boruta_py.py:201\u001b[0m, in \u001b[0;36mBorutaPy.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    189\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m    Fits the Boruta feature selection with the provided estimator.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m        The target values.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/boruta/boruta_py.py:319\u001b[0m, in \u001b[0;36mBorutaPy._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39m# basic result variables\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_ \u001b[39m=\u001b[39m confirmed\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 319\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(n_feat, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mbool)\n\u001b[1;32m    320\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_[confirmed] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_weak_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(n_feat, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.int = int\n",
    "np.float = float\n",
    "np.bool = bool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from boruta import BorutaPy\n",
    "import shap\n",
    "\n",
    "categorical_columns = ['site', 'cid', 'gasource', 'magecat', 'medu_r2', 'meducat_r2', 'paritycat', 'wttiming',\n",
    "                        'priorcsec', 'anyanc', 'anctri', 'ancvisits', 'ancvisitscat', 'vitcaliron', 'ttvaccine', 'hiv',\n",
    "                        'bpmeas', 'urinetest', 'anyus', 'lb', 'bsex', 'multiple', 'bagmask',\n",
    "                        'bathed', 'antehem', 'posthem', 'hypertensive', 'transverse', 'oblique',\n",
    "                        'breech', 'malp', 'induction', 'infdeliv', 'inffu', 'unplanhosp', 'hospcomp', 'seizures',\n",
    "                        'mantibiotics', 'corticosteroid', 'oxytocics', 'bldtrans', 'dcsuction', 'magsulfate',\n",
    "                        'hysterectomy', 'episiotomy', 'rentown', 'waterimp', 'waternotimp', 'water30min', 'sanitation',\n",
    "                        'floormat', 'cookfuel', 'bicycle', 'motorbike', 'vehicle', 'electricity', 'television',\n",
    "                        'refrigerator', 'computer', 'flipphone', 'smartphone', 'pregout', 'fuout', 'ltfdeliv']\n",
    "\n",
    "numerical_columns = ['gaenrl', 'mage', 'schyears', 'parity', 'numfamily', 'numrooms']\n",
    "\n",
    "target_variable = 'pretermalg'\n",
    "\n",
    "cols_to_read = categorical_columns + numerical_columns + [target_variable]\n",
    "\n",
    "df = pd.read_csv('data.csv', usecols=cols_to_read, dtype=str)\n",
    "df['pretermalg'] = pd.to_numeric(df['pretermalg'], errors='coerce')\n",
    "df = df.dropna(subset=['pretermalg'])\n",
    "df['pretermalg'] = df['pretermalg'].replace({2: 0})\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[categorical_columns + numerical_columns], \n",
    "                                                    df[target_variable], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Imputation for training data\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='unknown')\n",
    "\n",
    "# Ensure all numerical columns are numeric and contain no non-numeric values\n",
    "X_train[numerical_columns] = X_train[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "X_test[numerical_columns] = X_test[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Apply imputers\n",
    "X_train[numerical_columns] = num_imputer.fit_transform(X_train[numerical_columns])\n",
    "X_train[categorical_columns] = cat_imputer.fit_transform(X_train[categorical_columns])\n",
    "\n",
    "# Target Encoding\n",
    "target_encoder = ce.TargetEncoder()\n",
    "X_train_encoded = target_encoder.fit_transform(X_train[categorical_columns], y_train)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numerical_columns])\n",
    "\n",
    "# Combine categorical and numerical data\n",
    "X_train_final = np.hstack([X_train_encoded, X_train_scaled])\n",
    "\n",
    "# Preprocessing for test data (transform only)\n",
    "X_test[numerical_columns] = num_imputer.transform(X_test[numerical_columns])\n",
    "X_test[categorical_columns] = cat_imputer.transform(X_test[categorical_columns])\n",
    "X_test_encoded = target_encoder.transform(X_test[categorical_columns])\n",
    "X_test_scaled = scaler.transform(X_test[numerical_columns])\n",
    "X_test_final = np.hstack([X_test_encoded, X_test_scaled])\n",
    "\n",
    "# Feature selection\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
    "feat_selector.fit(X_train_final, y_train)\n",
    "selected_features_train = X_train_final[:, feat_selector.support_]\n",
    "selected_features_test = X_test_final[:, feat_selector.support_]\n",
    "\n",
    "results = {}\n",
    "# Model Training and Evaluation\n",
    "models = {\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"CatBoostClassifier\": CatBoostClassifier(silent=True),\n",
    "    \"LGBMClassifier\": LGBMClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_pred_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = auc_score\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"AUC: {auc_score}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc_score:.2f})\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Identify the best model\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# SHAP analysis\n",
    "explainer = shap.Explainer(best_model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, feature_names=categorical_columns + numerical_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
